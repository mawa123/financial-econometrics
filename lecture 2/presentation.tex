\documentclass[a4paper, 11pt]{beamer}

\usepackage{polski}
\usepackage[utf8]{inputenc}

\mode<presentation> {
	\usetheme{Frankfurt}
	\setbeamercovered{transparent}
	\usecolortheme{default}
}

\title{Ekonometria Finansowa}
\subtitle{Jednowymiarowe modele szeregów czasowych}
\author{mgr Paweł Jamer\thanks{pawel.jamer@gmail.com}}

\begin{document}

	\begin{frame}
		\titlepage
	\end{frame}
	
	\section{Biały szum}
	
	\begin{frame}{Biały szum}
		\begin{block}{\textbf{Biały szum}}
			Białym szumem nazwiemy szereg czasowy $\epsilon_t$ niezależnych zmiennych losowych o tym samym rozkładzie taki, że \begin{eqnarray*}
				\mathbb{E}\left(\epsilon_t\right) & = & 0,\\
				\mbox{Var}\left(\epsilon_t\right) & = & \sigma^2.
			\end{eqnarray*} Biały szum oznaczać będziemy symbolem $\mbox{WN}\left(0, \sigma^2\right)$.
		\end{block}
		\begin{alert}{\textbf{Uwaga}}
			Bardziej złożone modele szeregów czasowych wykorzystują biały szum do opisu niepewności pomiaru opisywanych przez nie wielkości.
		\end{alert}
	\end{frame}
	
	\section{Błądzenie losowe}
	
	\begin{frame}{Błądzenie losowe}
		\begin{block}{\textbf{Błądzenie losowe (bez dryftu)}}
			Szereg czasowy $p_t$ nazwiemy błądzeniem losowym bez dryftu, jeżeli spełnia on równanie \[
				p_t = p_{t-1} + \epsilon_t,
			\] gdzie
			\begin{itemize}
				\item $\epsilon_t$ --- biały szum.
			\end{itemize}
		\end{block}
		\begin{alert}{\textbf{Uwaga.}}
			Uzupełniając powyższy wzór o niezerową stałą $\alpha$ \[
				p_t = \alpha + p_{t-1} + \epsilon_t
			\] uzyskujemy proces błądzenia losowego z dryftem.
		\end{alert}
	\end{frame}
	
	\begin{frame}{Ceny instrumentów finansowych}
		\begin{block}{\textbf{Hipoteza}}
			Cena instrumentu finansowego $p_t$ jest błądzeniem losowym.
		\end{block}
		Rozważmy model \[
			p_t = \alpha + \rho p_{t-1} + \epsilon_t.
		\]
		Prawdziwość powyższej hipotezy jest równoznaczna z tym, że:
		\begin{itemize}
			\item $\hat{\rho}$ statystycznie nie różni się od jedności,
			\item $\epsilon_t$ jest białym szumem.
		\end{itemize}
		Ponadto, jeżeli na zadanym poziomie istotności zachodzi:
		\begin{itemize}
			\item $\hat{\alpha} = 0,$ to $p_t$ jest błądzeniem losowym bez dryfu,
			\item $\hat{\alpha} \neq 0,$ to $p_t$ jest błądzeniem losowym z dryfem.
		\end{itemize}
		\begin{alert}{\textbf{Uwaga.}}
			Z powodu możliwej niestacjonarności $p_t$ estymacja powyższego równania
			jest problematyczna.
		\end{alert}
	\end{frame}
	
	\begin{frame}{Właściwości błądzenia losowego}
		\begin{columns}[onlytextwidth]
			\begin{column}{0.5\textwidth}
				\textbf{Błądzenie losowe bez dryftu} \[
					p_t = p_{t-1} + \epsilon_t,
				\] \[
					p_t = p_0 + \sum_{h=0}^{t} \epsilon_{t-h},
				\] \[
					\mathbb{E}\left(p_t\right) = p_0,
				\] \[
					\mbox{Var}\left(p_t\right) = t \sigma^2_{\epsilon_t}.
				\]
			\end{column}
			\begin{column}{0.5\textwidth}
				\textbf{Błądzenie losowe z dryftem} \[
					p_t = \alpha + p_{t-1} + \epsilon_t,
				\] \[
					p_t = p_0 + t \alpha + \sum_{h=0}^{t} \epsilon_{t-h},
				\] \[
					\mathbb{E}\left(p_t\right) = p_0 + t \alpha,
				\] \[
					\mbox{Var}\left(p_t\right) = t \sigma^2_{\epsilon_t}.
				\]
			\end{column}
		\end{columns}
	\end{frame}
	
	\begin{frame}{Stopy zwrotu instrumentów finansowych}
		Rozważmy model błądzenia losowego bez dryftu dla logarytmu cen pewnego instrumentu finansowego \[
			\log\left(p_t\right) = \log\left(p_{t-1}\right) + \epsilon_t.
		\] Model ten przekształcić możemy do postaci \[
			r_t = \log\left(\frac{p_t}{p_{t-1}}\right) = \epsilon_t.
		\]
		\begin{alert}{\textbf{Uwaga.}}
			Badanie czy logarytm cen $p_t$ instrumentu finansowego jest błądzeniem losowym
			sprowadza się do ustalenia, czy logarytmiczne stopy zwrotu $r_t$ tego instrumentu są białym szumem.
		\end{alert}
	\end{frame}
	
	\begin{frame}{Krytyka}
		Optymalna prognoza ceny instrumentu finansowego na okres przyszły, to przyjęcie ceny tego instrumentu z okresu bieżącego.
		\\~\\
		Nie uwzględnia się rentowności zależnej od ryzyka.
	\end{frame}
	
	\section{Modele ARMA}

	\begin{frame}{Proces AR}
		Zdefiniujmy operator \[
			\varphi\left(B\right) = I - \varphi_{1} B - \ldots - \varphi_{p} B^{p},
		\] gdzie $p \in \mathbb{Z}_{+}.$
		\begin{block}{\textbf{Proces AR}}
			Słabo stacjonarny szereg czasowy $X_t$ nazwiemy procesem AR (autoregresyjnym) rzędu $p,$ jeżeli spełnia on równanie \[
				\varphi\left(B\right) X_t = \epsilon_{t},
			\] gdzie $\epsilon_{t} \sim \mbox{WN}\left(0, \sigma^2\right).$
		\end{block}
		\begin{alert}{\textbf{Oznaczenie.}}
			Proces AR rzędu $p$ oznacza się symbolem $\mbox{AR}\left(p\right).$
		\end{alert}
	\end{frame}

	\begin{frame}{Proces MA}
		Zdefiniujmy operator \[
			\theta\left(B\right) = I + \theta_{1} B + \ldots +\theta_{q} B^{q},
		\] gdzie $q \in \mathbb{Z}_{+}.$
		\begin{block}{\textbf{Proces MA}}
			Słabo stacjonarny szereg czasowy $X_t$ nazwiemy procesem MA (średniej ruchomej) rzędu $q,$ jeżeli spełnia on równanie \[
				X_t = \theta\left(B\right) \epsilon_{t},
			\] gdzie $\epsilon_{t} \sim \mbox{WN}\left(0, \sigma^2\right).$
		\end{block}
		\begin{alert}{\textbf{Oznaczenie.}}
			Proces MA rzędu $q$ oznacza się symbolem $\mbox{MA}\left(q\right).$
		\end{alert}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Definicja}
		\begin{block}{\textbf{Proces ARMA}}
			Słabo stacjonarny szereg czasowy $X_t$ nazwiemy procesem $\mbox{ARMA}\left(p, q\right),$ jeżeli spełnia on równanie \[
				\varphi\left(B\right) X_t = \theta\left(B\right) \epsilon_{t},
			\] gdzie $\epsilon_{t} \sim \mbox{WN}\left(0, \sigma^2\right).$
		\end{block}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Estymowanie funkcji autokorelacji (ACF)}
		\begin{block}{\textbf{Estymator funkcji autokorelacji}}
			Jako estymator funkcji autokorelacji procesu $X_t$ możemy przyjąć \[
				\hat{\rho}_h = \frac{\sum_{t=h}^{T}\left(X_t - \overline{X}\right)\left(X_{t-h} - \overline{X}\right)}{\sum_{t=1}^{T}\left(X_t - \overline{X}\right)^2}
			\]
		\end{block}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Estymowanie funkcji autokorelacji częściowej (PACF)}
		\begin{block}{\textbf{Estymator funkcji autokorelacji częściowej}}
			Jako estymator funkcji autokorelacji częściowej procesu $X_t$ możemy przyjąć \begin{eqnarray*}
				\alpha_{0} & = & 1,\\
				\alpha_{1} & = & \phi_{1,1} = \hat{\rho}_1,\\
				\alpha_{h} & = & \phi_{h,h} = \frac{
					\hat{\rho}_h - \sum_{j=1}^{h-1} \phi_{h-1,j}{\hat{\rho}_{h-j}}
				}{
					1 - \sum_{j=1}^{h-1} \phi_{h-1,j} \hat{\rho}_j
				}, h = 2, 3, \ldots,
			\end{eqnarray*} gdzie $\phi_{i,j}$ to rozwiązania układu Yule'a-Walkera.
		\end{block}
		\begin{alert}{\textbf{Intuicja.}}
			Współczynnik autokorelacji częściowej mierzy korelację między zmiennymi
			$X_t$ oraz $X_{t-h}$ po eliminacji wpływu zmiennych pośrednich.
		\end{alert}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Identyfikacja na podstawie ACF oraz PACF}
		\begin{itemize}
			\item Jeżeli proces jest typu $\mbox{AR}\left(p\right),$ to funkcja
				autokorelacji powoli maleje, natomiast funkcja autokorelacji częściowej
				staje się statystycznie równa zero od wartości $p + 1.$
			\item Jeżeli proces jest typu $\mbox{MA}\left(q\right),$ to funkcja
				autokorelacji staje się statystycznie równa zero od wartości $q + 1,$
				natomiast funkcja autokorelacji częściowej powoli maleje.
			\item Jeżeli proces jest typu $\mbox{ARMA}\left(p,q\right),$ to funkcja
				autokorelacji oraz funkcja autokorelacji częściowej łagodnie zanikają.
		\end{itemize}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Identyfikacja na podstawie kryteriów informacyjnych}
		\begin{block}{\textbf{Idea}}
			Należy oszacować modele $\mbox{ARMA}\left(p,q\right)$ dla wszystkich możliwych
			kombinacji parametrów $p=1,2,\ldots,P$ oraz $q=1,2,\ldots,Q,$ a następnie obliczyć
			dla nich wartości wybranego kryterium informacyjnego. Minimalna wartość kryterium
			wyznacza optymalną parę parametrów $p$ i $q.$
		\end{block}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Kryteria informacyjne}
		Niech $L_{p,q}$ oznacza wiarogoność modelu $\mbox{ARMA}\left(p, q\right).$
		\begin{block}{\textbf{Kryterium informacyjne Akaike (AIC)}}
			\[
				\mbox{AIC}_{p,q} = -2\ln L_{p,q} + 2\left(p + q + 1\right)
			\]
		\end{block}
		\begin{block}{\textbf{Bayesowskie kryterium informacyjne (BIC)}}
			\[
				\mbox{BIC}_{p,q} = -2\ln L_{p,q} + \left(p + q + 1\right) \ln T
			\]
		\end{block}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Podział metod estymacji}
		\textbf{Metody estymacji:}
		\begin{itemize}
			\item Metody estymacji parametrów modelu $\mbox{AR}\left(p\right):$
			\begin{itemize}
				\item równania Yule'a-Walkera,
				\item metoda najmniejszych kwadratów,
				\item metoda największej wiarogodności.
			\end{itemize}
			\item Metody estymacji parametrów modelu $\mbox{ARMA}\left(p,q\right):$
			\begin{itemize}
				\item metoda największej wiarogodności.
			\end{itemize}
		\end{itemize}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Idea metod estymacji}
		\begin{block}{\textbf{Równania Yule'a-Walkera}}
			Równania Yule'a-Walkera to liniowy układ równań pozwalający na wyrażenie
			parametrów autoregresji za pomocą współczynników autokorelacji. Oszacowania
			parametrów modelu AR(p) otrzymujemy zastępując we wspomnianym układzie
			współczynniki autokorelacji ich estymatorami, a następnie rozwiązując układ.
		\end{block}
		\begin{block}{\textbf{Metoda najmniejszych kwadratów}}
			Wykorzystanie klasycznej MNK do stacjonarnego szeregu czasowego typu AR(p).
			Uzysane w ten sposób estymatory będą zgodne z estymatorami metody największej
			wiarogodności.
		\end{block}
		\begin{block}{\textbf{Metoda największej wiarogodności}}
			Metoda polegająca na maksymalizacji funkcji największej wiarogodności procesu
			$\mbox{ARMA}\left(p,q\right).$
		\end{block}
	\end{frame}
	
	\begin{frame}{Proces ARMA}
		\framesubtitle{Prognoza}
		Interesuje nas prognoza na $h$ okresów w przód: \[
			X_{t+h} = \sum_{k=1}^{p} \rho_{k} X_{t+h-k} + \sum_{k=0}^{q} \theta_{k} \epsilon_{t-k},
		\] gdzie $\theta_0 = 0.$
		\\~\\
		Możemy wyrazić ją jako warunkową wartość oczekiwaną: \begin{eqnarray*}
			\hat{X}_t\left(h\right) & = & \mathbb{E}\left(X_{t+h} \mid X_t, X_{t-1}, \ldots\right),\\
			\mathbb{E}\left(X_{t+j} \mid X_t, X_{t-1}, \ldots\right) & = & \begin{cases}
				X_{t+j}, & j \leq 0,\\
				\hat{X}_t\left(j\right), & j > 0,
			\end{cases}\\
			\mathbb{E}\left(\epsilon_{t+j} \mid \epsilon_t, \epsilon_{t-1}, \ldots\right) & = & \begin{cases}
				\epsilon_{t+j}, & j \leq 0,\\
				0, & j > 0.
			\end{cases}
		\end{eqnarray*}
	\end{frame}
	
	\begin{frame}{Proces ARIMA}
		\begin{block}{\textbf{Proces ARIMA}}
			Szereg czasowy $X_t$ nazwiemy procesem $\mbox{ARIMA}\left(p, d, q\right),$ jeżeli
			szereg czasowy $\Delta^{d} X_t$ jest procesem $\mbox{ARMA}\left(p, q\right).$
		\end{block}
		Z powyższej definicji wynika, że proces $\mbox{ARIMA}\left(p, d, q\right)$ jest opisywany przez następujące równanie: \[
			\varphi\left(B\right)\left(\Delta^{d} X_{t}\right) = \theta\left(B\right) \epsilon_{t}.
		\]
	\end{frame}
	
	\begin{frame}{Multiplikatywny proces ARMA}
		\framesubtitle{Intuicja}
		Niech proces $X_t$ charakteryzuje równanie \[
			\varphi_X\left(B\right) X_t = \theta_X\left(B\right) \epsilon_t,
		\] natomiast proces $\epsilon_t$ równanie \[
			\varphi_{\epsilon}\left(B\right) \epsilon_t = \theta_{\epsilon}\left(B\right) \eta_t,
		\] gdzie $\eta_t \sim \mbox{WN}\left(0, \sigma^2\right).$
		Składając powyższe równania uzyskujemy \[
			\varphi_{\epsilon}\left(B\right) \varphi_X\left(B\right) X_t = \theta_X\left(B\right) \theta_{\epsilon}\left(B\right) \eta_t.
		\]
		\begin{alert}{\textbf{Uwaga.}}
			Powyższe złożenie dwóch procesów ARMA pozostaje nadal procesem ARMA.
		\end{alert}
	\end{frame}
	
	\begin{frame}{Multiplikatywny proces ARMA}
		\framesubtitle{Definicja}
		\begin{block}{\textbf{Multiplikatywny proces ARMA}}
			Szereg czasowy $X_t$ nazwiemy multiplikatywnym procesem
			$\mbox{ARMA}\left(p, q\right)\times\left(P,Q\right)_s,$ jeżeli
			spełnia on równanie \[
				\Phi\left(B^s\right) X_t = \Theta\left(B^s\right) \epsilon_t,
			\] gdzie
			\begin{itemize}
				\item $\Phi$ --- operator analogiczny do $\varphi$ rzędu $P,$
				\item $\Theta$ --- operator analogiczny do $\theta$ rzędu $Q,$
				\item $\epsilon_t$ --- proces $\mbox{ARMA}\left(p,q\right).$
			\end{itemize}
		\end{block}
	\end{frame}
	
	\begin{frame}{Multiplikatywny proces ARMA}
		\framesubtitle{Właściwości}
		\begin{alert}{\textbf{Reprezentacja.}}
			Proces $\mbox{ARMA}\left(p, q\right)\times\left(P,Q\right)_s$ jest
			specyficznym przypadkiem procesu $\mbox{ARMA}\left(p+sP,q+sQ\right).$
		\end{alert}
		\\~\\
		\begin{alert}{\textbf{Estymacja.}}
			Estymacja parametrów multiplikatywnych procesów ARMA odbywa się przez osobną
			estymację parametrów każdego z procesów ARMA wchodzących w jego skład.
		\end{alert}
	\end{frame}
	
	\begin{frame}{Sezonowy proces ARIMA}
		\begin{block}{\textbf{Sezonowy proces ARIMA}}
			Szereg czasowy $X_t$ nazwiemy sezonowym procesem
			$\mbox{ARIMA}\left(p, d, q\right)\times\left(P,D,Q\right)_s,$
			jeżeli spełnia on równanie \[
				\Phi\left(B^s\right) \phi\left(B\right) \Delta_s^D \Delta^d X_t = \Theta\left(B^s\right) \theta\left(B\right) \epsilon_t,
			\] gdzie
			\begin{itemize}
				\item $\epsilon_t$ --- biały szum,
				\item $\Delta_s^D \Delta^d X_t$ --- proces stacjonarny.
			\end{itemize}
		\end{block}
	\end{frame}
	
	\section{Modele GARCH}
	
	\begin{frame}{Model ARCH}
	\end{frame}
	
	\begin{frame}{Model GARCH}
	\end{frame}
	
	\begin{frame}{Model GARCH-M}
	\end{frame}
	
	\begin{frame}{Model EGARCH}
	\end{frame}
	
	\begin{frame}{Model TGARCH}
	\end{frame}
	
	\section{Model ECM}
	
	\begin{frame}{Definicja}
		\begin{block}{\textbf{Model korekty błędem (ECM)}}
			\[
				\Delta y_{t} =
					\mu +
					\alpha \left(y_{t-1} - \beta_{0} - \beta_{1} x_{t-1}\right) + 
					\sum_{i=1}^{k-1} \theta_{i} \Delta y_{t-i} + 
					\sum_{i=0}^{k-1} \gamma_{i} \Delta x_{t-i} + 
					\epsilon_{t}
			\]
		\end{block}
		\textbf{Interpretacja:}
		\begin{itemize}
			\item $y_{t-1} = \beta_{0} + \beta_{1} x_{t-1}$ --- równanie równowagi
				długookresowej,
			\item $y_{t-1} - \beta_{0} - \beta_{1} x_{t-1}$ --- odchylenie od 
				równowagi długookr.,
			\item $\alpha$ --- współczynnik opisujący szybkość dostosowywania się 
				zmiennej objaśnianej do poziomu równowagi długookresowej (w 
				stabilnym modelu $\alpha < 0$).
			\item $\theta_{i}, \gamma_{i}$ --- współczynniki opisujące dynamikę
				krótkookresową.
		\end{itemize}
	\end{frame}
	
	\begin{frame}{Stosowalność}
		\begin{alert}{\textbf{Uwaga.}}
			Twierdzenie Grangera o reprezentacji gwarantuje nam możliwość
			zastosowania mechanizmu korekty błędem względem skointegrowanych
			szeregów czasowych.
		\end{alert}
	\end{frame}
	
	\begin{frame}{Estymacja}
		\begin{enumerate}
			\item Estymacja parametrów równania równowagi długookresowej \[
				y_{t-1} = \beta_{0} + \beta_{1} x_{t-1}.
			\]
			\item Skonstruowanie szeregów czasowych \begin{eqnarray*}
				\epsilon_{t} & = & y_{t} - \beta_{0} - \beta_{1} x_{t},\\
				\Delta x_{t} & = & x_{t} - x_{t-1},\\
				\Delta y_{t} & = & y_{t} - y_{t-1}.\\
			\end{eqnarray*}
			\item Estymacja parametrów równania modelu korekty błędem \[
				\Delta y_{t} =
					\mu +
					\alpha \epsilon_{t-1} + 
					\sum_{i=1}^{k-1} \theta_{i} \Delta y_{t-i} + 
					\sum_{i=0}^{k-1} \gamma_{i} \Delta x_{t-i} + 
					\epsilon_{t}
			\]
		\end{enumerate}
	\end{frame}

	\section*{}

	\begin{frame}
		\center
		\Huge \bfseries
		Pytania?
	\end{frame}

	\begin{frame}
		\center
		\Huge \bfseries
		Dziękuję za uwagę!
	\end{frame}

\end{document}